<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Plagiarism Checker | Viper - Free Plagiarism Checker and Scanner Software</title>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <link href="http://feeds.feedburner.com/ViperScanner" rel="alternate" type="application/rss+xml" title="ScanMyEssay RSS. News &amp; Updates"/>
        <link href="http://www.scanmyessay.com/css/main.css" rel="stylesheet" type="text/css"/>
        <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript"></script>
        <script src="http://code.jquery.com/ui/1.8.21/jquery-ui.min.js" type="text/javascript"></script>
        <link rel="shortcut icon" href="http://www.scanmyessay.com/favicon.ico"/>

        <script type="text/javascript">
            $(document).ready(function () {
                $("#exp-content").hide();
                $("#s1").click(function () {
                    $("#exp-content").fadeIn("slow"); //fadeIn
                    $("#s1").hide();
                });
                $("#h1").click(function () {
                    $("#exp-content").hide("slow");
                    $("#s1").show();
                });
            });
            
        </script>

        <style type="text/css">
        	
        	#plg-notes {
        		margin: 15px 0;
        	}
        .no-underline {
        	text-decoration:none;
        }
        .matched-text 
        {
        	text-decoration:none;
        	background-color: #fff86a /*#febbbb*/; 	
        }
        #document-text a {
        	color: #000;
        }
        #document-text a:hover {
        	color: #000;
        }        
        .divcenter {
        	margin: 5px 0;
        	padding-left: 1px;
        }
        .coner-radius 
        {
        	-moz-border-radius:3px;
        	-webkit-border-radius:3px;
        }
        #h1 {
        	display: block;
        	text-align: right;
        }
        
        #main 
        {
        	padding: 5px 5px 20px 5px;       	
        }
        #menu ul li h2 
        {
           	margin: 5px 5px;
           	color: #ccc;
        }
          
        	.main-container-top{
        	
        		border: 1px solid #fcefa1; /*need removing this*/
        		background: #fbf9ee;
        		width: auto;
        		height: auto;
        		margin-right: 0;
        		margin-top: 40px;
        		float: none;
        	}
            .main-container-mid {
        	    border: 1px solid #aaa; /*need removing this*/
            	width: auto;
            	height:auto;
            	margin: 5px 0;
            }
            .main-container-bottom {
            	border: 1px solid #aaa; /*need removing this*/
            	width: auto;
            	height:auto;
            	margin: 2px 0;	
            }
            
        	.ie-h1-fix {
        		margin-top: 0px;
        		padding-bottom: 3px;
        	}
        	
        	.red-text {
        		color: #c40028;
        	}
        	
        	#rounded-corner
{
	font-family: "Lucida Sans Unicode", "Lucida Grande", Sans-Serif;
	font-size: 9px;
	margin: 1px;
	text-align: left;
	border-collapse: collapse;
	
}

#rounded-corner tbody 
{
	width: inherit;
	height: 300px;
	overflow: scroll;
	overflow-x: hidden;
}

#rounded-corner thead th.rounded-location
{
	/* background: #ccc;  #b9c9fe;*/
	-moz-border-radius-topleft: 3px;
	-webkit-border-top-left-radius: 3px;
    width: 40%;
   /* background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(247,247,247,1)), color-stop(50%,rgba(132,132,132,1)), color-stop(50%,rgba(132,132,132,1)), color-stop(100%,rgba(229,229,229,1))); /* Chrome,Safari4+ */
  /* background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(226,226,226,1)), color-stop(50%,rgba(219,219,219,1)), color-stop(51%,rgba(209,209,209,1)), color-stop(100%,rgba(254,254,254,1))); /* Chrome,Safari4+ */
  background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(239,239,239,1)), color-stop(50%,rgba(219,219,219,1)), color-stop(52%,rgba(209,209,209,1)), color-stop(100%,rgba(242,242,242,1))); /* Chrome,Safari4+ */
}
#rounded-corner thead th.rounded-doc-title
{
    width: 30%;
}
#rounded-corner thead th.rounded-plg-wrd-count
{
}
#rounded-corner thead th.rounded-mst-plg-pecnt
{
}
#rounded-corner thead th.rounded-unq-wrds-mtch
{
}
#rounded-corner thead th.rounded-unq-mtch-pecnt
{
	background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(239,239,239,1)), color-stop(50%,rgba(219,219,219,1)), color-stop(52%,rgba(209,209,209,1)), color-stop(100%,rgba(242,242,242,1))); /* Chrome,Safari4+ */
	/*background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(226,226,226,1)), color-stop(50%,rgba(219,219,219,1)), color-stop(51%,rgba(209,209,209,1)), color-stop(100%,rgba(254,254,254,1))); /* Chrome,Safari4+ */
	/*background: #ccc;*/
	-moz-border-radius-topright: 3px;
	-webkit-border-top-right-radius: 3px;
}
#rounded-corner th
{
	padding: 8px;
	font-weight: normal;
	font-size: 13px;
	color: #555;
	/*background: #ccc;*/
	/*background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(226,226,226,1)), color-stop(50%,rgba(219,219,219,1)), color-stop(51%,rgba(209,209,209,1)), color-stop(100%,rgba(254,254,254,1))); /* Chrome,Safari4+ */
	background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(239,239,239,1)), color-stop(50%,rgba(219,219,219,1)), color-stop(52%,rgba(209,209,209,1)), color-stop(100%,rgba(242,242,242,1))); /* Chrome,Safari4+ */
}
#rounded-corner td
{
	padding: 8px;
	background: #f9f9f9;
	border-top: 1px solid #fff;
	color: #555;
	height: auto;
}

#rounded-corner tfoot td.rounded-foot-left
{
	/*background: #ccc;*/
	background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(242,242,242,1)), color-stop(50%,rgba(219,219,219,1)), color-stop(51%,rgba(209,209,209,1)), color-stop(100%,rgba(226,226,226,1))); /* Chrome,Safari4+ */
	-moz-border-radius-bottomleft: 3px;
	-webkit-border-bottom-left-radius: 3px;
}
#rounded-corner tfoot td.rounded-foot-right
{
	background: #ccc;
	background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(242,242,242,1)), color-stop(50%,rgba(219,219,219,1)), color-stop(51%,rgba(209,209,209,1)), color-stop(100%,rgba(226,226,226,1))); /* Chrome,Safari4+ */
	-moz-border-radius-bottomright: 3px;
	-webkit-border-bottom-right-radius: 3px;
}
#rounded-corner tbody tr:hover td
{
	background: #dadada;
	background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(255,255,255,1)), color-stop(50%,rgba(241,241,241,1)), color-stop(51%,rgba(225,225,225,1)), color-stop(100%,rgba(246,246,246,1))); /* Chrome,Safari4+ */
	/*background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(235,241,246,1)), color-stop(50%,rgba(171,211,238,1)), color-stop(51%,rgba(137,195,235,1)), color-stop(100%,rgba(213,235,251,1))); /* Chrome,Safari4+ */
	/*background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(255,255,255,1)), color-stop(50%,rgba(244,250,249,1)), color-stop(51%,rgba(231,245,243,1)), color-stop(100%,rgba(248,252,251,1))); /* Chrome,Safari4+ */
	/*background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(255,255,255,1)), color-stop(50%,rgba(234,255,229,1)), color-stop(51%,rgba(209,255,199,1)), color-stop(100%,rgba(240,255,237,1))); /* Chrome,Safari4+ */
	background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(255,255,255,1)), color-stop(50%,rgba(255,238,229,1)), color-stop(51%,rgba(255,219,199,1)), color-stop(100%,rgba(255,243,237,1))); /* Chrome,Safari4+ */
}
        </style>
       
    </head>
    <body>
        <div id="wrap">
            
            <div id="top">
                <div id="top-left-tr">
                    <a href="http://www.scanmyessay.com" title="ScanMyEssay">
                        <span>Plagiarism Checker</span>
                    </a> 
                </div>

                <div id="top-tr">
                    <a href="http://www.scanmyessay.com/feedback/index.php" title="Contact us">Contact us</a>
                    | 
                    <a href="http://www.scanmyessay.com/universities.php">Universities</a>
                    |
                    <a href="http://www.scanmyessay.com/viper-background.php">History</a>
                    |
                    <a href="http://www.scanmyessay.com/testimonies.php">Testimonies</a>
                    |
                    <a href="http://www.scanmyessay.com/press/index.php" title="Viper Press">Press</a>
                    |
                    <a href="http://www.scanmyessay.com/about-us.php" title="About us">About us</a>
                    |
                    <a href="http://www.scanmyessay.com/sitemap.php" title="Sitemap">Sitemap</a>
                    |
                    <a href="http://www.scanmyessay.com/help/index.php" title="Help">Help</a>
                    |
                    <a href="http://www.ukessays.com/essay-help.php" title="Essay help" target="_blank">Essay help</a>
                    |
                    <a href="http://www.scanmyessay.com/rss/index.php" title="RSS">RSS</a>
                    |
                    <a href="http://www.scanmyessay.com/login/index.php" title="Log in">Log in</a>
                </div>    
            </div>
               
            <div id="menu">
                <ul>
                    <li>
                        <h2>Plagiarism Report For 'Final Report_21009807.docx'</h2>
                    </li>
                </ul> 
            </div>

            <div id="main">
                <div class="main-container-top coner-radius">
                    <h1 class="red-text ie-h1-fix">
                        How does Viper work.....?
                    </h1>
                    <a id="s1" class="no-underline" href="#">[+] Read more..</a>
					<div id="exp-content">
                        Viper scans your work against over 10 billion web pages and work previously 
                        submitted to our firm. Once the scan is completed, the report delivers content 
                        that may match these other sources, including links to the sites that contain 
                        the same content.
                        <br />
                        <br />
                        <b class="red-text">What Do the Results Mean?</b><br />
                        If the report sends back positive matches to content found elsewhere, there is no need to panic and assume you have plagiarised your work. Instead, review the report carefully and consider the following:
                       
                        <ul>
                        <li>
                        Is the material an entire quote, a sentence, or a fragment of 4-5 words often found together? Viper will show a match where there is a string of five or more 
                        words that are the same as your work. Even if this is not actually plagiarism, it is important that Viper does not ignore these fragments as they draw your 
                        attention to any sentences where the writer has &#39;rephrased&#39; parts of the 
                        original material without referencing the source.
                        </li> 
                            
                        <li>If it was intended to be a quote that you were going to attribute to the source, 
                            did you remember to properly reference it? Sometimes, Viper will identify 
                            matching material that is available on websites, but the reference might have 
                            been found within another source. Just because the work has content that matches 
                            a particular website does not mean that every possible source where it appears 
                            has to be referenced. Just make sure that at least one reference covers that 
                        content.
						</li>
                        <li>Did you actually use a footnote and it was just simply not picked up by Viper? 
                            This review is just a means of double-checking that all references have been 
                            included.
						</li>
                        <li>Could Viper have just picked up a phrase that you used more than once in your 
                            document? This may be a way to ensure that your writing is tight rather than 
                            repetitive or relies on overly used phrases.
						</li>    
                        <li>Did you use too many direct quotes? Viper checks for direct quotes and delivers 
                            an overall percentage of words it views as direct quotes. Clearly, this should 
                            not be too high as work that relies too heavily on other material is not 
                            &#39;original&#39;.
						</li>
                        </ul>
                            <b class="red-text">A Guide on Viper Results</b>
                            <br/>This guide explains how Viper can identify matching content when it scans your work:
                            <br/>
                            <br/><b class="red-text">Overall plagiarism rating 6% or less : </b>
                            <br/>The results are that it is highly unlikely that this document contains plagiarised material. A careful check will only be necessary if this is a lengthy document. For example, a 6% result within a 15,000 word essay would be of concern because it could mean that direct quotes are too lengthy or there are too many places where a reference was not listed.<br/>
                            <br/><b class="red-text">Overall plagiarism rating 6% - 12% : </b>
                            <br/>The results are that there is a low risk that the document contains any plagiarised material. Most of the matching content will probably be fragments. Review your report for any sections that may not have been referenced properly.<br/>
                            <br/><b class="red-text">Overall plagiarism rating 13% - 20% : </b>
                            <br/>The results are that there is a medium risk that the document contains any plagiarised material. There may be sections that match websites so it is important to check that proper credit was attributed to the other sources. The scan may not have detected quotation marks or footnotes that were used. For example, if an opening quotation mark was included but there was not a closing quotation mark, then this could explain the higher result. <br/>
                            <br/><b class="red-text">Overall plagiarism rating 21%+ : </b>
                            <br/>The results are that there is a high risk that the document contains plagiarised material. If the overall rating is this high, you need to check your report very carefully. It may be that there are a lot of matching fragments and the software has not identified all direct quotes , but it is critical that you go through the entire document and address every phrase or fragment that the scan has flagged to reduce this percentage.<br/>
                            <a id="h1" class="no-underline" href="#">[-] hide</a>
                        
                    </div>
                </div>
                <div class="main-container-mid coner-radius">
                    <table id="rounded-corner" summary="URL found to be copied">
                        <thead>
                            <tr>
                                <th scope="col" class="rounded-location">Location</th>
                                <th scope="col" class="rounded-doc-title">Title</th>
                                <th scope="col" class="rounded-plg-wrd-count">Words Matched</th>
                                <th scope="col" class="rounded-mst-plg-pecnt">Match (%)</th>
                                <th scope="col" class="rounded-unq-wrds-mtch">Unique Words Matched</th>
                                <th scope="col" class="rounded-unq-mtch-pecnt">Unique Match (%)</th>
                            </tr>
                        </thead>    
                        <tfoot>
                            <tr>
                                <td colspan="5" class="rounded-foot-left"><em>Documents found to be plagiarised</em></td>
                                <td class="rounded-foot-right">&nbsp;</td>
                            </tr>
                        </tfoot>
                        <tbody id="ajaxtable">
                            <tr><td><a href=http://stackoverflow.com/questions/15670933/opencv-java-load-image-to-gui target="_blank">http://stackoverflow.com/questions/15670933/opencv-java-load-image-to-gui</a></td><td>swing - Opencv java - Load image to GUI - Stack Overflow</td><td>59</td><td>1</td><td>59</td><td>1</td></tr>
                        </tbody>
                    </table>
                    
                </div>
                <div id="plg-notes" class="divcenter red-text">
                       <b> Matching Content: 1%</b>
                    </div> 
                <div class="main-container-bottom coner-radius">
                    <div id="document-text" class="divcenter">
                        <h2>Master Document Text</h2>
                        <!--<a href="" class="matched-text"> xyz </a> -->
                        <p> University of readingA Face Authentication SystemFinal Year ProjectProject Supervisor:   Hong WeiProject ID:  A-FACEModule Code:  SE3IP11Student<br /> Tom BedfordStudent Number:  21009807Submitted:  TBDAbstractComputerised Face authentication is vastly being integrated into today’s technologies<br /> systems. As an efficient and effortless method of character recognition this technology aspires to be prevalent in every-day activities with the aims<br /> of managing data and location access and delivering customized user experiences. This report illustrates the design, implementation and effectiveness<br /> of a proof of concept facial authentication system. The system utilises Viola-Jones methodology of feature extraction and PCA (Principal Component<br /> Analysis) to derive a fast and efficient means of digital face detection and verification. It features a configurable threshold acceptance value in<br /> order to handle a range of illumination levels which provide a challenging constraint in image analysis. The developed system can potentially<br /> complement an existing user authentication layer or operate as an independent authentication system. Its application can be easily extended to<br /> provide some form of greeting message or profile to future students attending a university open dayAcknowledgmentsHong Wei –<br /> supervisorContentsGlossary of Terms and Abbreviations4Introduction5Problem Articulation / Technical Specification5The Solution7Literature Reviews<br /> Implementation11Login Interface11Create Database Interface15Training Interface16Testing: Verification and Validation20Face Detection20Discussion<br /> Conclusion24Project Commentary24Social, Legal, Health & Safety and Ethical Issues24Reflection25References25Appendices28Appendix 128Primary Supervisor<br /> Secondary supervisor281Introduction302Background303Problem Statement313.1Objectives313.2Constraints313.3Assumptions314Technical Products315Crosscheck<br /> of approach336Health and Safety337Legal and Ethical348Examination Products349References3710Project Plan3810.1Technical Products3810.2Examination<br /> Products3810.3Time Plan for the proposed Project work39Appendix 21Glossary of Terms and AbbreviationsHCIHuman Computer InteractionLDALinear Detection<br /> AlgorithmPIDProject Initiation Document GUIGraphical User InterfaceMVCModel View ControllerAPIApplication Program InterfaceOpen CVOpen Computer<br /> VisionPCAPrincipal Component AnalysisPOSPoint of SaleDDFDDeep Dense Face DetectionIntroduction Biometric analysis has been a focused area of research<br /> for many years due to its distinctive features, ease of accessibility and potential industrial application such as government surveillance[1] and<br /> more commonly today HCI [2]. Technological advancements have provided more powerful and affordable hardware and open sourced software<br /> allowing the technology to be researched more actively. This has resulted in the rise of fully automated recognition systems that are now defining<br /> their presence in the world today. Although biometric evaluation such as finger print recognition has delivered more reliable results than face<br /> recognition it requires additional expensive hardware to install and demands focused interaction from its user. With the least overhead for system<br /> instalment, invasiveness and efficiency, facial recognition has become the most popular choice of biometric analysis.Facial recognition is the<br /> identification and verification of noticeable characteristics of a human face and in the field of image analysis it is leading the race in research<br /> as its speed and versatile application out weights previous methods.It is a task performed effortlessly by humans on a daily basis. The sheer<br /> complexity of the human brain can truly be admired whilst replicating this complex functionality in machine software. Distinctive features of the<br /> human face such as the nose, mouth and eyes are algorithmically recognised by object detection and associated to known geometrical shapes.Human to<br /> computer authentication is an integral functionality of many software systems as it manages data and/or location securityThis project explores the<br /> application of face detection and verification and its effectiveness as an authentication based system using the open vision library developed by IBM<br /> The main algorithmic features of the developed face authentication system in this project focus on the detection and verification of a human user<br /> The system efficiency, accuracy and speed is tested by serious of test on compiled face databases sourced from various establishments’ online<br /> repositories.Problem Articulation / Technical Specification The fundamental goals of the developed system in this study is the successful detection<br /> of a user’s face and the verification of a known users within a targeted face databases. Acceptance criteria is satisfied by LDA analysis determining<br /> whether the users extracted geometrical features fall within a given threshold in order to grant them access to the application. The threshold of<br /> acceptance will be adaptable to suit the needs of the systems environment which substantially dictates acceptance rates of the recognition process<br /> Illumination, user posture, direction, expression and face size are the greatest affecting factors in face recognition computation [4].It is assumed<br /> that users will present there face at an offset no greater than a 35 degree angle and the camera will be of sufficient quality to capture images<br /> an adequate resolution. The user will not be wearing items that obstruct large portions of the face. To provide a reliably secure authentication<br /> system recognition results must fall within a refined acceptance threshold that ensures access only to known users of the system. These assumptions<br /> and constraints where originally defined in the PID [Appendix 1] report referenced at the end of this document submitted at the beginning of<br /> project. To satisfy the project objectives derived in the PID each deliverable must meet its acceptance criteria. The proposed solutions are based on<br /> addressing three main modules of the system’s functionality, the GUI, face detection and verification functionality.The GUI must be developed to<br /> provide a simple interface for the user to detect and capture images of their face to be submitted as part of the authentication process. The GUI<br /> will also need to host a training screen where the user can select, load and train face databases prior to user verification.Figure. 1 Face<br /> authentication graphical user Interface design.Figure 1 illustrates the work flow of the proposed GUI. It can be seen that the programs user<br /> interface is built up of three main displays, the login, training and custom database screens. The login and training screens are essential to the<br /> systems core functionality for loading and training data and the custom database screen is to provide further customisation for creating and adapting<br /> databases. Developing the GUI in Java language will be less complex and time consuming than C++.This solution will be developed in Java CV [5] a<br /> ported version of the natively C++ Open CV library. The Open CV java library essentially wraps the C++ functionality in Java so that it can be<br /> utilised in Java code. JavaFX [6] will be used to develop the systems GUI allowing it be implemented as an MVC framework to allow the systems API<br /> be reused by other systems easily.Figure 2. Recognition process of the facial authentication system.The face detection functionality will be capable<br /> of acknowledging a human face by recognising geometrical features of a human face with the use of trained Haar-like feature cascade classifiers<br /> provided by the Open CV library [7]. The classifier iterates through image pixel data verify any know geometrical shapes whilst optimising its<br /> results using an AdaBoost algorithm [8]. To satisfy the systems acceptance criteria detection must successfully capture a frontal facing image<br /> an offset of 35 degree angle at a success rate of 90%.Detected images will then need to be normalised to conform to standardized dimensions of<br /> system and to reduce computation. This is achieved by resizing the detected image and then converting the colour channels to an average greyscale<br /> channel.Principal component analysis will be used reduce and optimise data representation. It is the most popular and efficient LDA’s (Linear<br /> Detection Algorithm) in developing facial recognition technologies today. The PCA approach The SolutionFigure. 3 Proposed system solution<br /> proposed solution as displayed in figure.3 will be developed using a Java wrapped Open CV library Java CV to enable simpler development of the GUI’s<br /> so that efforts can be focused towards the main algorithmic features of the system. JavaFX library will be used to implement an MVC structure<br /> allowing the main functionality of the system to be utilised or integrated into other systems easily.The open vison library supplies a variety of<br /> classifiers that have been trained to detect geometrical feature shapes of a human face. The classifier ‘haarClassifier_frontalFace_alt.xml’ that<br /> will be used to perform face detection is based on viola jones methodology [9]. The detected image is then normalized by rescaling and<br /> conversion to reduce computation and conform to dimensional standards of the recognition algorithm. As the Java CV library does not incorporate the<br /> Face Recognizer class [10] a custom PCA class will be developed by the use of Open CV and third party math libraries.This solution aims to verify the<br /> user and associate them to the relevant profile though the login interface. A password is then entered to ensure a secure authentication system. It<br /> was decided not to use the facial authentication system developed in this project as a stand-alone security system and should instead compliment an<br /> existing system as an extra layer of security. The main algorithm of the system will be principal component analysis to calculate Eigen Decomposition<br /> and effectively derive Eigen Faces [11]. The system will initially provide functionality to load directories of face images from local memory to<br /> application and may be expanded to access online repositories depending on objective deliverance deadlines met.The application GUI will be based on<br /> the module illustrated in figure.1 earlier in this document. The design will provide methods to standardize loaded images prior to verification or<br /> detection computation. The original determined acceptance criteria of the PID documents technical products have been refined and illustrated below in<br /> figure.4.Technical ProductAcceptance CriteriaGraphical user interfaceThe GUI must provide functionality for the user to capture, load and train<br /> images. It must also provide a login screen for authentication and a platform where verification can be tested.Capturing and storing images as<br /> graphical filesThe system will feature functionality for the user to capture and save images and trained data sets.Computing face detectionA user’s<br /> face will be successfully detected and represented in the video camera feed. To satisfy acceptance it should be able to detect a face on offset no<br /> greater than 35 degrees.Computing face verificationImages from a trained database should be able to match features of an input image within an<br /> adequate threshold at 75% success rate with a minimal false negative match rate.Integrate face database into systemThe user will be able to load a<br /> face database from local memory into the application and functionality to train the data set. Images must be standardized to comply with system<br /> standards.Display recognition results of acceptance and rejection ratesThe system will display acceptance threshold rates and associated face matches<br /> It will also show rejection rates of verifications outside of a set threshold.Figure.4 Refined acceptance criteria of technical productsLiterature<br /> ReviewsMethods of human authentication have previously and still are performed using unique credentials such as personal ID cards, passports, unique<br /> passwords and phrases. These methods of authentication often require some form of physical interaction or focus from its user. The form of this<br /> uniquely identifiable data has largely been an extension of a person such as a passport. Biometrics offer the convenience of no extra materials<br /> assets or memory cognition as they are physical features that individually identify a person.The face is the most exposed definitive characteristic<br /> of a human and therefore can be analysed with little demand of interaction from the person, if any. A person need only look towards the scanning<br /> device which in this case is a camera for seconds and recognition can be successfully performed in real time or from a captured image frame on<br /> reasonable low quality images. Face recognition is a popular method of identification in government surveillance systems [12]. It can be carried<br /> on multiples entities simultaneously with speed which is extremely effective in crowds of people.In the infantile stages of facial analysis feature<br /> extraction was performed manually. The automation of this process in real time was introduced by Paul Viola and Michael Jones in 2001 [9].<br /> does the algorithm detect facial features in real time but performs this with a simpler complexity of computation allowing computers with low<br /> processing power to utilise the software. The Viola-Jones method of Haar-like feature classification revolutionised face detection techniques. All<br /> methods of computerised human identification operates on the basis that a set of uniquely identifiable data is submitted by a user to the system<br /> where it is compared and associated to its relevant data within a determined threshold of acceptance to verify authentication.In December last year<br /> the company bioID [13] released a facial recognition software solution for apple hardware. The software allows the use of face authentication<br /> authorize access to devices such as the IPad and IPhone and is steadily integrating it services towards bank payments, POS and other high security<br /> transactions. It features a patented liveness detection algorithm [14] to determine whether the user is fact a real person or not. Liveness<br /> is become a common practice in face detection in the efforts to prevent spoofing and unauthorized access. BioID’s software also host a rich<br /> development package that can be easily integrated into software development to encourage developers to incorporate facial authentication into future<br /> software applications. Other programming language versions of this software are slowly becoming available.Cognitec is another company offering<br /> multipurpose face recognition system solutions for use in security authentication in fields such as law enforcement, border control and ID fraud<br /> protection. The company has been researching facial recognition technology in collaboration with the university of Surrey and Technical University of<br /> Dresden since 2010 [15].In the stride for more secure and reliable biometric analysis recognition, methods are being expanded to extract<br /> features that can determine an inanimate user. For instance to combat finger print scanner spoofing thermo-detection hardware is being added to<br /> scanners in order to register a heat signature that would suggest a real user is attempting authenticate [16]. In regards to enhancing<br /> verification security with liveness detection, tracking eyelid movement is proving an effective means of countering falsified verification.Again last<br /> year there was the release of an advanced facial recognition system called DDFD [17]. The detection algorithm has been extended from the<br /> of Viola-Jones methodology of face detection and uses a convolution neural network to learn a composition of facial features. Impressively this<br /> algorithm has been trained on a database containing over 21 thousand images. This is one of the most robust face detection systems on the<br /> today as it can successfully detect partial faces, upside down oriented faces and largely obstructed faces.In a few months from now Microsoft windows<br /> will be introducing a new component dubbed ‘Windows Hello’ [18] to their popular operating system. This new functionality will allow windows users<br /> login using face recognition technologies. Microsoft claim this will be more secure than older authentication methods like passwords and will<br /> strengthen computer security as a whole.There are many organisations investing largely in face recognition development as the vision of effortless<br /> human computer interaction becomes a reality. The United States National Intelligence Agency launched a development program in early 2014 named<br /> The aims of Janis is to compile a broad database of facial morphology derived from online digital media and sources to understand and develop more<br /> sophisticated and optimal facial analysis techniques. This rich database will provide an intensive testing plane for facial recognition algorithms<br /> and will accelerate their development.A high street store has invested in face recognition software to verify high profile customs such as<br /> celebrities so that a high quality customer service can be delivered. The investment was motivated after a well renowned celebrity entered the store<br /> one day and the manager serving them had no knowledge of their social status missing the opportunity of a lucrative sale and repeat business<br /> This example demonstrates the versatile application of face authentication systems being applied in services other than security.Well renowned<br /> security conferences such as the Black Hat [21] and Def Con [22] conferences attract some of the world’s leading specialists in information<br /> under one roof to diverge and discuss security practices and technologies. An article posted shortly after the Black Hat conference back in 2009<br /> Washington DC voiced concerns over facial biometric use for authentication. The salient features of the report demonstrated how early versions of<br /> face authentication integrated into Lenovo, Asus and Toshiba machines could be hacked and did not fulfil the necessary requirements. Although facial<br /> analysis methods are becoming more sophisticated and reliable for security there are still concerns over the handling and management of biometric<br /> data due to its permanent nature.A group of biometric computation experts demonstrated at the 2015 Black Hat conference how retinal analysis could be<br /> re-engineered and potentially hacked to falsify authentication [23]. This form of re-engineering firstly required gaining access to the stored<br /> biometrical data but illustrated that even the most complex of biometric analysis could be exploited. Amongst the concerns of biometrical data<br /> management their also worries that the integration of facial recognition systems increase surveillance coverage and reducing the public privacy.The<br /> huge leap in face analysis development has also attracted further developments in existing recognition techniques such as speech recognition [24].<br /> a desired means of HCI this is a contestant not far behind face recognition.PCA is one of the most successful face detection algorithms to date. PCA<br /> is the method of reducing dimensionality of a data space (observational variables) and extracting data from the feature space (Independent Variables<br /> which are needed to represent the data economically. The feature space in this case is the Eigen Space in which derived principal components are<br /> projected to deduce Eigen values.For other image analysis systems who are also challenged by lighting factors technologies such as Infrared and<br /> thermal imaging is be introduced. For instance infrared technologies are currently being used in carparks to simulate a daytime like environment to<br /> extract car number plates in poor lighting conditions [25]. This allows image recognition methods to extract the characters of the number<br /> Infrared scanners used in this capacity are expensive to install and maintain but would provide more mobility of the system and more potential<br /> recognition environments.Extended face recognition research investigates the use of thermal cameras to collect image data. This allows a better<br /> representation of a 3D face model as it does not detect facial items such as glasses and records only heat signature data [26]. The<br /> environments lighting conditions are a CCP of the systems functionality and its placement must be considered careful or additional technology will be<br /> needed. Implementation Login InterfaceA basic GUI framework was initially implemented and later enhanced to satisfy the needs of interaction to the<br /> system. The JavaFX library used to develop the GUI allowed the creation of an MVC based model isolating the API and GUI allowing modular reuse of the<br /> system. Figure.5 illustrates a screen shot of the login interface.Figure.5 Screenshot of login screen graphical user interfaceThe login screen<br /> provides an area where the user can test user authentication. On first time login of the system access is granted using an administrative username<br /> and password so that an initial face image data set can be loaded and trained. After the trained data has been produced it is then written to memory<br /> so that then a known user can login using the facial verification functionality.The login screen hosts a video capture stream activated by the ‘Start<br /> Stop Camera’ button. The video capture objects implemented throughout the system is sourced from the ‘opencv.videoio’ library. Video stream data is<br /> handled in memory using Open CV’s Matrices object format ‘Mat’. To comply with Java AWT [Java AWT] image display standards ‘Mat’ objects are<br /> converted to a Java.awt Image using Open CV’s image codecs in order to display them in the GUI. This conversion functionality is displayed below in<br /> figure.6 protected Image Mat2Image(Mat frame) {// temporary bufferMatOfByte buffer = new MatOfByte();// encode image frame into PNG formatImgcodecs<br /> imencode(".PNG", frame, buffer);// build image from encoded buffered datareturn new Image(new ByteArrayInputStream(buffer.toArray()));}Figure.6 Open<br /> CV Matrix to Java AWT conversion functionEach grabbed frame from the video stream is processed using the Face Detector class developed for this<br /> application. The face detector class loads into memory a trained cascade classifier ‘haarcascade_FrontalFace_alt.xml’ supplied by the Open CV library<br /> The grabbed frame is converted to greyscale to reduce colour channels and effectively data to process. Greyscale co nversion functionality is<br /> incorporated in Open CV’s Imgproc module originally derived from OpenCV core module. During system runtime there are multiple areas of the<br /> application where image type conversion is computed. The class AppTools.class has been developed to manage these conversions and has been referenced<br /> in the Appendices of this report.The face detection algorithm is performed on each grabbed frame of the video sequence to determine a human face<br /> through Haar-like feature cascade classification. This involves loading the classifier into the Cascade Classifier object supported by the Open CV<br /> library. The frame is then prepares for detection by converting the frame to greyscale and calculating the minimum face size. The following code seen<br /> in figure.7 illustrates this preparation. //create cascade classifierCascadeClassifier faceDetector = new CascadeClassifier();//absolute path to<br /> classifiersString classifierPath = "C:\\Users\\user\\workspace\\AFaceAuthenticationSystem\\src\\application\\Resources\\HaarCascades\\haarcascade<br /> frontalface_alt.xml";//load classifiersfaceDetector.load(classifierPath);//Create Mat canvas to store detectionsMatOfRect faceDetections = new<br /> MatOfRect();Mat greyScaleImg = new Mat(); </w:t// convert the frame in gray scale Imgproc.</w:tcvtColor(imageMat, greyScaleImg, Imgproc.COLOR_BGR<br /> GRAY); </w:t// compute minimum face size (20% of the frame height) </w:tif (absoluteFaceSize == 0) {</w:t </w:t></wint height = greyScaleImg.rows<br /> w:t></wif (Math.round(height * 0.2f) > 0) {</w:t></w absoluteFaceSize = Math.round(height * 0.2f);</w:t></w:r>< }</w:t></w }</w:t </w:t></w:r<br /> wFigure.7 Cascade classification preparationDetection is then performed on the prepared frame. This process iterates through the frames pixel data to<br /> distinguish known geometrical features of the classifier. </w:t> // detect faces faceDetector.detectMultiScale(greyScaleImg, faceDetections<br /> Objdetect.CASCADE_SCALE_IMAGE, new Size( </w:t></w:r><w:r><w:rPrabsoluteFaceSize, absoluteFaceSize), new Size());//create array of face detections<br /> computedRect[] faceArray = faceDetections.toArray();  </w:t//iterate through the imagefor (int i=0; i<faceArray.length; i++){//find rectangle<br /> contours of facesImgproc.rectangle(imageMat, faceArray[i].tl(), faceArray[i].br(), new Scalar(0, 250, 0, 255), 3);//crop image of faceMat crop<br /> imageMat.submat(faceArray[i]);Figure.8 Calculate face detections functionality from Face Detector classDetected faces in each frame are then outlined<br /> with a green rectangle of the calculated absolute face dimensions in figure.9 to signify face detection to the user. Figure.9 Face DetectionOnce the<br /> user has logged in for the first time added there detected face to a dataset and computed Eigen faces through the training interface an input image<br /> can then be verified against the applications trained data on login authentication. This is done by a similar process to training the data set where<br /> firstly the average face is subtracted from the input image and then the weights and distances of the image minus averages are calculated. Figure<br /> and 11 demonstrate this processes logic.private Matrix getWeights(Matrix matrix, int numOfEigenFaces) {Matrix eigenFaces = new Matrix(cache<br /> getEigenFaces());Matrix selectedEigenFaces = eigenFaces.getMatrix(0,eigenFaces.getRowDimension() <= numOfEigenFaces ? eigenFaces.getRowDimension<br /> numOfEigenFaces, 0,eigenFaces.getColumnDimension() - 1);return matrix.times(selectedEigenFaces.transpose());}Figure.10 Calculate weights of input<br /> image functionalityprivate double[] getDistances(Matrix inputWeights) {double[] weightsData = inputWeights.getArray()[0];double[][] tempWeights<br /> subtractFromEachRow(cache.getEigenWeights(), weightsData);tempWeights = squareNonMatrix(tempWeights);double[] distances = new double[tempWeights<br /> length];for (int i = 0; i < tempWeights.length; ++i) {double total = 0;for(int j=0;j<tempWeights[i].length ;++j) {total += tempWeights[i][j<br /> distances[i] = total;}return distances;}Figure.11 Calculate distances of input image functionalityOnce the distance and weights of the input image<br /> have been determined the previously trained data set is read into the application in order to compare these values. Loading in the trained data into<br /> memory on the login process reduces computational time opposed to having to train datasets on each login attempt. The trained data is read back into<br /> memory with the functionality illustrated in figure.12.private void loadEigenCache() {// read eigen cache into memory FileInputStream fs;try {fs<br /> new FileInputStream("C:\\Users\\user\\workspace\\AFaceAuthenticationSystem\\EigenCache\\eigenCache.db");ObjectInputStream os = new ObjectInputStream<br /> fs);eigenCache = (EigenCache) os.readObject();// close streamsos.close();fs.close();} catch (IOException e) {e.printStackTrace();} catch<br /> ClassNotFoundException e) {e.printStackTrace();}}Figure.12 Load cached trained data into memory functionalityHere a comparison can be made of the<br /> calculated Eigen Vectors and Values to determine the distance from the average face. This is then accepted or rejected if the distance is within the<br /> set threshold.  Create Database InterfaceThe create database interface provides an area where a first time or existing user can capture<br /> detections and either create a customized database or add to an existing one. Essentially as set of images can be obtained and saved as displayed in<br /> figure.13. The interface utilises the Face detection algorithm and Open CV video capture stream components used in the login screen.Figure.13 Create<br /> database interface screenshotTraining InterfaceLimitations of the ported Open CV library Java CV where discovered here. The native C++ Open CV<br /> library supports a Face Recognizer class that features PCA (Principal Component Analysis) computation functionality. As this module of the Open CV<br /> has not yet been ported to the Java CV library a custom PCA class was implemented in Java with the aid of third party apache commons Math [27]<br /> Jama Matrices libraries [28]. The custom PCA class developed for this project has referenced in the Appendices of at the end of the report.The<br /> training interface provides the user the ability to load, train and write trained data sets to memory. It also provides a testing ground for trained<br /> data sets where the user can select an image to perform face verification on the loaded database. Matches, if any, are displayed along with their<br /> calculated thresholds. The thresholds represent the distance from the average face. These calculated thresholds are then accepted if they fall within<br /> a set threshold of acceptance. In order to manage the illumination changes of the different environments in which the system may be used a slider has<br /> been implemented in the training interface to allow the threshold of acceptance to be adjusted. PCA concatenates each row of pixel data from an image<br /> of the dataset into a one dimensional array. Once each image is represented as a row a Matrix is built up of each image as a row. The logic to method<br /> can be seen in figure.14 below.Figure.14 Face matrix preparationOnce the faces matrix has been constructed pixel values of the data are normalised<br /> between zero and one. During the greyscale averaging computation the RGB values are combined to create large decimal numbers. Normalization is<br /> performed to unify variable proportions and standardize data in the system. Figure.15 displays the system normalization function. private double<br /> normalizeImageData(int[][] image) {double[][] returnData = new double[image.length][image[0].length];// Normalise data between 0 and 1for (int<br /> faceInd = 0; faceInd < image.length; ++faceInd) {double min = (double) getMinValue(image[faceInd]);double max = (double) getMaxValue(image[faceInd<br /> for (int j = 0; j < image[faceInd].length; ++j)returnData[faceInd][j] = ((((double) image[faceInd][j])) - min) / (max - min);}return returnData<br /> Figure.15 Normalisation functionNext the mean is subtracted from each row and a covariance matrix is compiled. This was carried out with the aid of<br /> the Apache Commons Math library. The Apache library is then again used to calculate Eigen vectors and values. Eigen Vectors represent the direction<br /> of data and the associated Eigen Values represent the distance of the data from the average face. The average face used to determine Eigen<br /> decomposition is produced by finding the average data from the compiled face matrix as described in figure.16. The calculate Eigen decomposition<br /> function.private void calculateEigenVectorsAndValues() {// Log.append("Computing covariance matrix...");// Compute covariance matrixRealMatrix matrix<br /> new Covariance(new BlockRealMatrix(faceMatrixMinusAverages).transpose()).getCovarianceMatrix();// Log.append("Computing eigen decomposition<br /> Get the eigenvalues and eigenvectorsEigenDecomposition eigen = new EigenDecomposition(matrix);eigenValues = eigen.getRealEigenvalues();// Transpose<br /> so that eigenvalues are in vectors/columnseigenVectors = eigen.getV().transpose().getData();}Figure.16 calculate Eigen decomposition functionThe<br /> Eigen vectors that represent the most variance are then removed and a set amount of Eigen vectors are selected to represent the Principal Components<br /> A function was developed to compute the principal components and then sort them into descending order prior to selection as displayed in figure<br /> private void calculatePrincipalComponents() {int numOfComponents = eigenVectors.length;// Get principle componentsArrayList<PrincipalComponent<br /> principalComponents = new ArrayList<PrincipalComponent>();for (int i = 0; i < numOfComponents; i++) {double[] eigenVector<br /> numOfComponents];for (int j = 0; j < numOfComponents; j++) {eigenVector[j] = eigenVectors[i][j];}principalComponents.add(new PrincipalComponent<br /> eigenValues[i], eigenVector));}// sort componentsCollections.sort(principalComponents);Iterator<PrincipalComponent> iterator = principalComponents<br /> iterator();int count = 0;double[][] tempVectors = new double[3][eigenVectors.length];double[] tempValues = new double[3];while (iterator.hasNext<br /> PrincipalComponent pc = iterator.next();if (count < 3) {tempVectors[count] = pc.eigenVector;tempValues[count] = pc.eigenValue;} else {eigenVectors<br /> count - 3] = pc.eigenVector;eigenValues[count - 3] = pc.eigenValue;}count++;}}Figure.17 calculate Principal Component functionprivate void<br /> calculateEigenFacesAndWeights () {int pixelTotal = faceMatrixMinusAverages[0].length;int imageTotal = faceMatrixMinusAverages.length;int vectorTotal<br /> eigenVectors.length;// calculate eigen facesdouble[][] eigenFace = new double[vectorTotal][pixelTotal];for (int i = 0; i < vectorTotal; ++i) {double<br /> squaredSum = 0;for (int j = 0; j < pixelTotal; ++j) {for (int k = 0; k < imageTotal;<br /> eigenVectors[i][k];}squaredSum += eigenFace[i][j] * eigenFace[i][j];}double norm = Math.sqrt(squaredSum);for (int j = 0; j < pixelTotal; j<br /> eigenFace[i][j] /= norm;}}// get specified amount of eigen facesthis.eigenFaces = new Matrix(eigenFace).getMatrix(0,eigenFace.length<br /> numOfEigenFacesSelected ? eigenFace.length - 1 : numOfEigenFacesSelected, 0,eigenFace[0].length - 1).getArray();this.eigenWeights =<br /> faceMatrixMinusAverages).times(new Matrix(eigenFaces).transpose()).getArray();}Figure. 18 calculate Eigen face and weights functionFigure<br /> illustrates the programming logic use to calculate the Eigen faces and corresponding weights. The use of a third party library called JAMA was used<br /> to support matrices computation. The derived Eigen faces are converted back to Java AWT buffered images and written as Jpeg format into memory in<br /> order to visualize the variance. A sample of 10 computed Eigen faces are displayed in figure.19.// construct buffered image from<br /> facesBufferedImage[] constructedEFaces = new BufferedImage[faceMatrix_array.length];for (int i = 0; i < faceMatrix_array.length; i<br /> constructedEFaces[i] = getImageByEigenValues(eigenWeights[i], eigenFaces);}Figure.19 Constructing Eigen Faces to Jpeg images.Figure.20 Calculated<br /> Eigen faces for visualizing variance.From observing the Eigen faces in Figure.20 It can be seen that the first few Eigen faces represent the most<br /> amount of variance leading to the least variance.Figure.21 illustrates a screen shot of face verification matches and thresholds results after<br /> performing a search.Figure.21 Screen shot of Face verification results after search performedTesting: Verification and Validation Face<br /> DetectionDuring face detection runtime multiple faces where detected and highlighted in the visible frames of the video stream as demonstrated in<br /> Figure.22. Figure.22 Multiple faces detectedAs the system only wishes to process one user at a time the most prominent face is selected as the<br /> detected face. Also as seen in figure.22 the robustness of the cascade classifier can be observed as the algorithm has successfully located a human<br /> face in the background from a picture with very little facial detail.Face detection is performed successfully within the specified offset and<br /> adequate illumination. Without adequate lighting conditions the face detection success rate drops dramatically.With large data sets Eigen<br /> decomposition can take a substantial amount of time.A serious of tests where carried using the XM2VS database compliments of the University of Surrey<br /> the AT&T face database supplied by the University of Cambridge [30] and the Yale database from the UCSD Computer Science Engineering Department<br /> Each of these database contain frontal facing greyscale channel images. The Yale database has much more variation in face gestures and lighting than<br /> the other two. The statistics and length of time taken to train of each database is recorded in figure.23 DatabaseNumber of ImagesTraining Time<br /> minutes)Training Time Per Image (milliseconds)Xm2vts2,36112.654322.00Xm2vts Sub Sample400.2145.35Yale1650.9245.60AT&T4012.2765.67Figure.23 Training<br /> statistics of three test face databasesThe face recognition system was tested with a range of thresholds to determine percentages of acceptance rates<br /> The bar chart illustrated in figure.24 shows these results.Figure.24 Recognition results for xm2vts and AT&T databaseThe results show better<br /> acceptance rates for the xm2tvs compared to the AT&T database. Illumination levels largely dictate the effectiveness of feature extraction. Images in<br /> the AT&T library are slightly lower quality of illumination than those in the xm2tvs library which could explain the lower acceptance rates of the<br /> results.It can be deduced from figure.24 that if the threshold is raise to high then the number of rejections and essentially false matches increase<br /> The threshold can be adjusted to suit the environments lighting to a certain degree although for optimal use of the system is advised that the<br /> illumination of the environment where the application will be used should be taken into considerate and accommodated for. In relation to the refined<br /> acceptance criteria of technical products illustrated in figure.4 a table has been comprised below to display whether determined criteria where met<br /> Technical ProductsCriteria Acceptance achievedCriteria Satisfaction descriptionGraphical User InterfaceAchievedThe graphical user interface has<br /> delivered interfaces for the user to capture, load and train image data sets. The GUI host an area to test verification on a trained data set and a<br /> login authentication page to test the verification security strength.Capturing and Storing Images as Graphical filesAchievedThe user can successfully<br /> save captured images and load images into application memory throughout the system.Compute Face DetectionAchievedA face detection algorithm was<br /> successfully developed and achieved the expected thresholds of a 85% acceptance rate for frontal images within an offset of a 35 degree<br /> Face RecognitionAchievedThe most demanding task of computing PCA without the support of the open CV library was achieved with the use of third party<br /> math and matrices libraries.Integrate Face DatabaseAchievedFunctionality was created to allow a user to load databases into the application memory<br /> Three database from various Universities where loaded into the application to train and test the verification functionalityDisplay Recognition<br /> results displaying acceptance and rejection ratesAchievedThe Training interface featured a text area where thresholds of acceptance and rejection<br /> where displayed along with verification statistics.Figure.25 reflection of technical products and their achievementsDiscussion On the basis of the<br /> deliverance of the proposed project deliverables the project was a reasonable success. All besides a few minor short falls the main demands of the<br /> system where met. Some data is being lost when computing the Eigen faces. It is suspected that during the normalization process variables of type<br /> double are being converted to integers resulting in the rounding of decimal numbers and thus this loss of data can be seen illustrated in figure<br /> This small loss of data has a minimal effect on the face recognition results although it could be refined to optimise the algorithms effectiveness<br /> given more time. Figure.26 Data loss through normalization and de-normalisation roundingThe strength of a stand-alone face recognition system used as<br /> a main authentication tool doesn’t appear to be the safest method of computer recognition as the face detection can be spoofed.Inanimate images<br /> photos can be held in front of the camera and a face is successfully detected. Open CV’s trained classifiers are robust enough to detect images with<br /> very little features. This poses a security issue as user recognition can be spoofed without the necessary precautions being implemented to counter<br /> such forgery. For the proposed application purpose of an open day student verification and greeting system it would be a realistic assumption that<br /> the database to train would only contain a few hundred images opposed to the 2,361 images trained from the xm2vts database. This would reduce the<br /> training time exceptionally and could allow for a new face to be detect, added to the database, trained then verified to display a greeting message<br /> in real time. As this would pose limitations to the growth of the database it would most probably be better to train the database prior to<br /> recognition to ensure the most effective result.Conclusion Naturally without the exposure and vision of completed project the originally determined<br /> success criteria in the PID document where very general and needed further definition. Time deadlines were also unrealistic as technical products<br /> such as the face verification functionality appeared to be far more demanding than first estimated. Although, with in consideration the project<br /> manage to deliver a fully functioning face authentication system and meet set objectives.As there is no liveness detection functionality featured the<br /> system can be fooled by holding a photo of a face which can be successfully detected. This concludes that this application should be used to<br /> compliment an existing security system as an extra layer and not as stand-alone security system due to potentially falsifying authentication<br /> demonstrated in the testing of this system.Extended goals such as integration of an online face database repository where not achieved due to time<br /> constraints and other coursework commitments.The acceptance objectives where satisfied to produce a functioning face authentication application<br /> Project Commentary Developing a custom PCA class consumed more project time than originally designated. This had an effect on the amount of time<br /> spent developing other system features.  In Hein sight I would of used the JNI to utilise Open CV C++ functionality. The native program language<br /> CV library contains a face recognizer class that can determine age and gender of a user. It also features a PCA class that would have saved much time<br /> when computing Eigen decomposition. Alternatively the project could have been developed using the native C++ library which would of provide more of a<br /> code learning curve but aided complicated computation such as principal component analysis.There was a steep learning curve in matrix mathematics and<br /> its application in code which has provided a motivational challenge.GIT Version control software was used to throughout the development of the<br /> project as online code back up and for rolling backing versions of code. Social, Legal, Health & Safety and Ethical Issues There are many<br /> arguments into the analysis and storage of biometrical data. As biometrics uniquely identify a person and cannot be replaced as sparingly as<br /> credentials like a password. If your authentication password or forms of identity such as bank card become compromised they can easily be changed<br /> although human like features such as the face are much more permanent.The ethical and social use of face recognition has been questioned much already<br /> as the public feel that their civil liberties and privacy are being invaded by the continuous surveillance and gathering of public data. With the<br /> ever growing technical strive to innovate methods of HCI and biometric analysis its view by some that we are slowly losing our privacy. An article<br /> released by abc news in late December 2015 voiced concerns about this privacy invasion [32].With current events in the world today,<br /> should make the public feel safer. It is unfortunate that quite often technology is abused in the wrong way but this shouldn’t affect the public<br /> decision to compromise and grow with technology.ReflectionThis project has delivered invaluable knowledge and experience working with an open source<br /> computer vision library. It has provided many challenges that has enhanced my academic skills in programming, time management, research and<br /> documentation. Many technical competencies have been exercised and improved through the completion of this project. I know have a clearer<br /> understanding and approach to unfamiliar programming language, libraries and practices.My managerial skills have excelled to meet the demands of this<br /> project which has supported the growth and refinement of my skill set.References[1] Jose Pagliery. (2014). FBI launches face recognition system<br /> Available: http://money.cnn.com/2014/09/16/technology/security/fbi-facial-recognition/. Last accessed 12th Jan 2016.[2] Reza Azad, Babak Azad, Nabil<br /> Belhaj Khalifa, Shahram Jamali. (2014). Real-Time Human-Computer Interaction Based on Face and Hand Gesture Recognition. International Journal in<br /> Foundations of Computer Science & Technology. 4 (4), 11.[3] OpenCV Developers Team. (2016). About OpenCV. Available: http://opencv.org/about.html<br /> Last accessed 13th Jan 2016.[4] Hewlett-Packard Development Company. (2015). HP IDOL. Available: https://my.vertica.com/docs/IDOL/Servers/IDOLServer<br /> Guides/html/Expert/index.html#IDOLExpert/Improve/FaceDetect_factors.htm. Last accessed 21st Jan 2016.[5] OpenCV Developers Team. (2016). OpenCV<br /> Available: http://docs.opencv.org/java/3.0.0/. Last accessed Feb 2nd 2016.[6] Oracle Developers Team. (2011). Oracle Java Documentation.Available<br /> http://docs.oracle.com/javase/8/javafx/get-started-tutorial/jfx-overview.htm#JFXST784. Last accessed Feb 2nd 2016.[7] Open CV Dev Team<br /> Cascade Classification. Available: http://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html. Last accessed Feb 10th 2016.[8] The<br /> MathWorks, inc. (2016). AdaBoost. Available: http://uk.mathworks.com/discovery/adaboost.html?refresh=true. Last accessed Feb 20th 2016.[9] Wikipedia<br /> Viola–Jones object detection framework. Available: https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework. Last accessed Feb<br /> th 2016.[10] Open CV Dev Team. (2016). Face Recognizer. Available: http://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_api.html. Last<br /> accessed Feb 21th 2016.[11] sis26@drexel.edu. (Unknown). Eigen Face Tutorial. Available: http://www.pages.drexel.edu/~sis26/Eigenface%20Tutorial.htm<br /> Last accessed Feb 27th.[12] Emily Miller. (2015). The Australian Government Has Started Using Facial Recognition Technology, And Hardly Anyone Is<br /> Talking About It.Available: http://junkee.com/the-australian-government-has-started-using-facial-recognition-technology-and-hardly-anyone-is-talking<br /> about-it/67366. Last accessed March 8th.[13] BioID Group. (2016). Biometric Solutions. Available: https://www.bioid.com/Solutions. Last accessed<br /> March 8th.[14] Gang Pan, Zhaohui Wu and Lin Sun (2008). Liveness Detection for Face Recognition, Recent Advances in Face Recognition, Kresimir<br /> Mislav Grgic and Marian Stewart Bartlett (Ed.), ISBN: 978-953-7619-34-3, InTech, Available from: http://www.intechopen.com/books/recent_advances_in<br /> face_recognition/liveness_detection_for_face_recognition[15] Cognitec Systems Group. (2015). Research. Available: http://www.cognitec.com/research<br /> html. Last accessed March 23rd 2016.[16] Stephanie Schuckers, Larry Hornak, Tim Norman, Reza Derakhshani, Sujan Parthasaradhi.<br /> Detection For Face Recognition.Available: http://www.biometrics.org/bc2002/2_bc0130_DerakhshabiBrief.pdf. Last accessed March 9th 2016.[17] Sachin<br /> Sudhakar Farfade, Mohammad Saberian, Li-Jia Li. (2015). Multi-view Face Detection Using Deep Convolutional Neural Networks.Available: http://arxiv<br /> org/pdf/1502.02766v3.pdf. Last accessed March 15th.[18] Joe Belfiore. (2015). Making Windows 10 More Personal and More Secure with Windows Hello<br /> Available: https://blogs.windows.com/windowsexperience/2015/03/17/making-windows-10-more-personal-and-more-secure-with-windows-hello/. Last accessed<br /> March 23rd 2016.[19] Michael Cooney. (2013). US intelligence wants to radically advance facial recognition software. Available: http://www<br /> networkworld.com/article/2225788/applications/us-intelligence-wants-to-radically-advance-facial-recognition-software.html. Last accessed March 30th<br /> Brenda Salinas. (2013). High-End Stores Use Facial Recognition Tools To Spot VIPs. Available: http://www.npr.org/sections/alltechconsidered<br /> high-end-stores-use-facial-recognition-tools-to-spot-vips. Last accessed March 15th.[21] Black Hat Group. (2016). Black Hat Homepage. Available<br /> https://www.blackhat.com/. Last accessed April 10th 2016.[22] Def Con Dev Group. (2016). Def Con Hompage. Available: https://www.defcon.org/. Last<br /> accessed April 15th 2016.[23] Marcus Colon. (2012). Black Hat: Biometric experts demonstrate reverse-engineering capability in iris scanning systems<br /> Available: http://www.scmagazineuk.com/black-hat-biometric-experts-demonstrate-reverse-engineering-capability-in-iris-scanning-systems/article<br /> Last accessed April 17th 2016.[24] Banking tech. (2011). Biometrics: the case for convenience. Available: http://www.bankingtech.com/47982/Biometrics<br /> the-case-for-convenience/. Last accessed Feb27th 2016.[25] wikipedia. (2016). Automatic number plate recognition. Available: https://en.wikipedia.org<br /> wiki/Automatic_number_plate_recognition. Last accessed April 15th 2016.[26] Wikipedia. (2016). Facial recognition system. Available: https://en<br /> wikipedia.org/wiki/Facial_recognition_system. Last accessed April 17th.[27] Apache Software Foundation. (2016). Commons Math: The Apache Commons<br /> Mathematics Library. Available: https://commons.apache.org/proper/commons-math/. Last accessed April 17th 2016.[28] Jama Dev Group. (2012). JAMA : A<br /> Java Matrix Package. Available: http://math.nist.gov/javanumerics/jama/. Last accessed April 20th 2016.[29] AT&T Laboratories Cambridge. (2002). The<br /> Database of Faces.Available: http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html. Last accessed April 20th 2016.[30] Dr Chi Ho Chan<br /> xm2vts database. Available: http://www.ee.surrey.ac.uk/CVSSP/xm2vtsdb/. Last accessed March 2nd. [31] UCSD Group. (2016). Yale Database. Available<br /> http://vision.ucsd.edu/content/yale-face-database. Last accessed March 2nd.[32] Simon Lauder. (2015). The Capability: Government's national facial<br /> recognition plan raises privacy concerns. Available: http://www.abc.net.au/news/2015-12-17/government's-facial-recognition-system-sparks-privacy<br /> concerns/7035980. Last accessed April 20th 2016.Appendices Appendix 1Project Initiation DocumentA Face Authentication SystemAuthor: Thomas<br /> BedfordModule: SE3IP11-15-6AProject ID: A-FACEDate: 9/10/2015 10:30amDocument Version: 1.0The current status of this document is: DraftPrimary<br /> SupervisorHong WeiSecondary supervisorJames FerrymanSupervisor’s check: For each item below the supervisor should circle  if it is satisfactory for<br /> this stage of the project; if it is not satisfactory then the supervisor should circle  and add a suitable comment to indicate the deficiency.<br /> supervisor should then sign below to confirm the <, and comments. CHECKLIST Comments, concerns and recommendationsBackground <br /> Technical Products  Crosscheck  Purchases  Health & Safety  Social, Legal & Ethical <br /> rules: The PID, with this form completed and signed by the supervisor, must be handed in to the student information centre (G47) AND submitted online<br /> on Blackboard by Friday 9th October 2015. If the deadline is not met, the student will face a penalty of 5 marks being deducted from<br /> module mark. It is expected that students will address any comments noted by their supervisor on this form in due course.IntroductionThis document<br /> initialises the project originally mandated in [1].  It clarifies what is expected and how it is to be done. As in any project initiation<br /> be uncertainties and they are identified where possible using the term TBD – to be determined. The background motivating this project is<br /> below in §2.  A concise statement of the objectives of this project is presented in §3. How these objectives are expected to<br /> summarised with a headline list of products listed in §4. The project is undertaken under the auspices of the final year project module SE3IP11-15-6A<br /> and this mandates that the examination products listed in §11 are delivered as well as the technical products listed in §4. An assurance<br /> intended technical products are likely to be adequate is given in §5 where the objectives and technical products are crosschecked. §12<br /> outline plan and shows the plausibility that delivering the products (both technical and examination) is feasible. The purchases expected in the plan<br /> are listed in §6. Mandatory safety, social, legal and ethical concerns are addressed in §7 and §8 respectively. All references referred<br /> document are listed in §10. Background  Technological advances striving to replicate human processes has resulted in biometric analysis<br /> focused area of research over the past twenty years. Biometric analysis of fingerprints, palm, eyes and faces have been a concentrated area of<br /> research. Humans perform face recognition on a daily basis effortlessly. Face recognition is one of the most non-intrusive methods of biometric<br /> analysis which makes it one of the most relevant applications.With so many applications such as video surveillance, human computer interaction and<br /> law enforcement biometric analysis is a focused area of research. The main issues regarding computing face recognition is the subject’s posture, age<br /> and lighting which restricts the usage of such systems to a controlled environment. With technological advances in hardware we draw closer to more<br /> efficient and reliable face authentication systems. Problem StatementThe proposed project has been analysed to extract any assumption §3.3 that<br /> be made about the project. The constraints of which this project will be completed in have been considered in §3.2. On the basis of the soundness<br /> the following assumptions, §3.3, it is deemed worthwhile to satisfy these objectives, §3.1, by delivering technical products subject<br /> constraints, §3.2, on how they may be developed and/or delivered.Objectives1) Develop a graphical user interface to capture and display images<br /> Capture images from a camera device and save images as graphic files.3) Implement Face detection algorithms on camera feed.4) Implement Face<br /> recognition algorithms on the camera feed.5) Integrate face data base into face authentication system.6) Display recognition results displaying<br /> rejection and acceptance rates.Constraints 1) The system will have to be in a controlled environment i.e good illumination. 2) Hardware such as<br /> camera resolution will dictate the quality of analysis results.3) Faces captured for recognition should be of a neutral gesture and posture.4) Faces<br /> captured for recognition will be frontal facing or within 20 degree angle.5) Project deadlines and delivery date.Assumptions1) Experiments will be<br /> carried out in a suitable environment i.e good lighting conditions, no foreign objects between the subject and camera.2) Images of faces stored in<br /> database will be frontal facing. Images captured for authentication will be frontal facing.3) System subjects will not be wearing obstructive facial<br /> items i.e. sunglasses, burka, head scarf.  4) Participants using the system will be aware of the handling of sensitive dataTechnical<br /> Graphical User InterfaceThe graphical user interface will provide a method of interaction from the user to the system. The user interface will<br /> display a camera feed and stored images for comparison. It will provide mechanisms for the user to customise and interact with the authentication<br /> system. No risks are involved in the completion of this product.Product 2: Capturing and storing images as graphical files. This product will enable<br /> a camera feed to be displayed through the GUI. It will allow the user to capture and store an image as a graphical file.Successful implementation of<br /> the camera feed into the GUI and the ability to capture and save graphical images with satisfy this products completion.Exceeding memory limits of<br /> storage, hardware failures and violation of privacy are the rick factors of the completion of this product.Product 3: Computing Face Detection The<br /> detection software will locate and track the face of a user. It will compute and draw a rectangle encompassing the contour features of the face. For<br /> this products completion the face detection software will correctly be able to locate and track a human user’s face. It will be able to illustrate<br /> through the camera feed the area of image that is being detected visible for the user.Hardware failures and loss of code are key risks to the<br /> completion of the product. Product 4: Computing Face RecognitionThe face recognition software will be able to compare the user’s captured image with<br /> a previously stored image of the user.The system should be able to successfully compare and recognise similarities of biometrical features within two<br /> images of a user’s face. Risk to the products completion include a weak understanding of supporting libraries such as image processing libraries and<br /> bad time management.Product 5: Integrate Face Database into systemThe integration of an online database that stores images and details of users faces<br /> into the system. The product must deliver the following tasks: Setup connections to an online database through the face authentication system. Some<br /> aspects of this products completion are TBD.Key Risk to its completions are connection issues with the online database and the completion of the<br /> previous products.Product 6: Display recognition results displaying rejection and acceptance rates.The product will display acceptance and rejection<br /> rates and recognition results to the user interface.Displaying the acceptance, rejection and recognition results will satisfy the completion of this<br /> product. Risks to this products completion are bad design of code restricting the developer from extracting such figures and late delivery of<br /> previous products.Crosscheck of approach Product 1Product 2Product 3Product 4Product 5Product 6Objective 1XObjective 2XObjective 3XObjective<br /> XObjective 5XObjective 6XThe products in which this project have been broken down into §4 satisfy the objectives proposed §3.1. Each<br /> a detailed solution to the tasks of each of the objectives stated in this document. Each product is associated with its own individual objective.The<br /> time plan illustrated in the tables of §10.3 details the time allocated for each technical and examination product. The technical deliverables<br /> scheduled to finish 2 weeks before the deadline of the final report examination product. This for extra testing, documentation and<br /> conclusions. The deliverable products §4 have been designated adequate proportions of time §10.3 in which they can be completed and<br /> Health and SafetyComputing for extensive amounts of time without regular breaks and unsupported seating position can cause eye strain, neck and back<br /> injuries and muscle strains.Using the software system in an inadequate environment i.e. outdoors when raining, a wet room.Using the camera in a<br /> cluttered area with objects on the floor (trip hazard). The area in which the camera will be used needs to be cleared from any trip hazards as the<br /> user will focusing on the interface.Legal and EthicalWhen using the face authentication system subjects need to be aware that the system will be<br /> handling there biometrics. Likewise participants need to be aware they are being monitored as uniformed used would be intrusive and a violation of<br /> privacy. Permission needs to be granted by the user before carrying out any analysis.An individual’s biometrics is a unique set of data that needs to<br /> be handle extremely sensitively and securely. You can get a new bank card with ease but it’s much harder to replace your face.The face authentication<br /> system proposed in this project should not be used within critical systems unless results can be guaranteed. There is no place for ambiguity in<br /> critical systems. For example the use of a recognition system that cannot guarantee reliable results in a critical system may falsely identify<br /> someone for a crime they did not commit. This can be damaging to a person reputation and the repercussions can be severe. </wExamination ProductsThe<br /> mandated examination products are as follows. Risks identified that may obstruct their completion are listed in [2] with cross-reference to this<br /> section.EX1. Name: PIDShort Description: The document that initiates this project and guides it thereafter.Acceptance Criteria: The PID must be<br /> written as a Microsoft Word or PDF document in compliance with the format and content instructions indicated in this document (the PID Master). All<br /> sections should be complete to a reasonable depth and quality, consistent with the stage of the project, that satisfies the technical judgement of<br /> the project supervisor and, if appropriate, the Company Partner. The sign offs on the cover page will be completed.EX2. Name: Autumn Term Week<br /> Logbook CheckShort Description: A formal check of project progress based on the logbook. Acceptance Criteria: The Student Information Centre staff<br /> and Project Co-Ordinator if necessary, must be convinced the project progress has been sufficient to date and that this progress has been adequately<br /> recorded in the logbook. The logbook must include a sign-off sheet that indicates that the logbook has been assessed by the supervisor on a weekly<br /> basis.EX3. Name: Project Progress ReviewShort Description: A formal check of project progress based on a checklist form. Acceptance Criteria: The<br /> Project Progress Review Individual Form’ must be completed by the student and supervisor and signed and submitted by the appropriate deadline.EX<br /> Name: Spring Term Week 6 DemonstrationShort Description: A formal presentation of the executable technical products of the project to the<br /> supervisor and internal moderator.Acceptance Criteria: During Week 6 of Spring Term, the student must demonstrate their project to their supervisor<br /> and internal moderator. The demonstration should show that the project’s technical products are on track to be completed by the end of the project.EX<br /> Name: PosterShort Description: A poster summarising a significant aspect of your work.Acceptance Criteria: A poster is constructed based on the<br /> template (TBD). It will be of a quality typical of an academic conference poster presentation. The content will introduce and explain some aspect<br /> claim of other facet of the project that the student deems most interesting and which is agreed by the supervisor.EX6. Name: SCARP AbstractShort<br /> Description: An abstract in a form typical of an academic conference.Acceptance Criteria: The abstract is written according to the academic template<br /> TBD). It will summarise the project with a focus on its achievements with respect to the objectives and technical products and what was learned. EX<br /> Name: SCARP PaperShort Description: A short paper in a form typical of an academic conference.Acceptance Criteria: The paper is written according to<br /> the academic template (TBD). It will describe the project with a focus on its achievements with respect to the objectives and technical products and<br /> what was learned. EX8. Name: Final ReportShort Description: The academic write up of the work achieved by the project in addressing the technical<br /> problem.Acceptance Criteria: The report shall be formatted according to provided rules (TBD). It shall have content assessable according to the<br /> criteria (TBD). It will include sections such as Introduction, Literature Survey, Problem Analysis, Solution Analysis, Implementation, Evaluation<br /> detail TBD).EX9. Name: Demonstration to Internal ExaminersShort Description: A formal presentation of the executable technical products of the<br /> project.  Acceptance Criteria: The working demonstration must be convincing to the examiners in terms of: showing a significant satisfaction of<br /> objectives through the operation of the developed technical products; showing that the work is substantially the product of the student’s efforts.EX<br /> Name: SCARP PresentationShort Description: A 10 minute presentation of your work in a conference setting.Acceptance Criteria: The paper is presented<br /> in a clear, coherent manner in the allotted time and plausible answers are given to such questions that are possible in the conference schedule<br /> typically two or three questions).EX11. Name: Project ArchiveShort Description: A CD containing all project documents.Acceptance Criteria: The CD<br /> must contain all the files and folders specified in the guidelines (TBD).References[1] A Face Authentication system, A-FACE, https://www.bb.reading<br /> ac.uk/webapps/blackboard/execute/launcher?type=Course&id=_113324_1&url=SE3IP11-15-6A: Individual Project (2015/16)/Course Documents/https://www.bb<br /> reading.ac.uk/bbcswebdav/pid-2778826-dt-content-rid-4576387_2/xid-4576387_2SE3IP11 List of Staff Proposed Projects 2015-16 v2.pdf, available from<br /> https://www.bb.reading.ac.uk/webapps/blackboard/content/listContent.jsp?course_id=_113324_1&content_id=_2570572_1&mode=reset). [2] RA1 Risk<br /> Assessment forms, https://www.bb.reading.ac.uk/webapps/blackboard/execute/launcher?type=Course&id=_113324_1&url=SE3IP11-15-6A: Individual Project<br /> Course Documents/https://www.bb.reading.ac.uk/bbcswebdav/pid-2570600-dt-content-rid-4564128_2/xid-4564128_2RISK_ASSESSMENT_FORM_RA2.docx, available<br /> from (https://www.bb.reading.ac.uk/webapps/blackboard/content/listContent.jsp?course_id=_113324_1&content_id=_2570572_1&mode=reset).[3]Wikipedia<br /> Face Recognition System, available from (https://en.wikipedia.org/wiki/Facial_recognition_system), visited on [01/10/2015].[4] Nova Next, The limits<br /> of face recognition, available from (http://www.pbs.org/wgbh/nova/next/tech/the-limits-of-facial-recognition/), visited on [28/09/2015].[5]PFC<br /> IonMarques.pdf, available from (www.ehu.eus/ccwintco/uploads/e/eb/PFC-IonMarques.pdf), visited on [03/10/2015][6]Face Rec Algorithms, available from<br /> http://www.face-rec.org/algorithms/), visited on [31/09/2015]. Project PlanTechnical ProductsTable 121 Technical ProductsProduct DeliveredTask IDTask<br /> DescriptionEffort(weeks)TP1.1Specify, Design1TP1.2Implement and test21TP1.3TP2.1Display camera feed in GUI1TP2.2Capture and save images as graphical<br /> files22TP2.3TP3.1Install and setup libraries and tools1TP3.2Compute face detection2TP3.3TP3.4Run and test face detection on stored images and camera<br /> feed23TP3.5TP4.1Install and setup libraries and toolsTP4.2Compute face recognition 2TP4.3TP4.4Run and test face recognition on stored images and<br /> camera feed2TP4.54TP4.6TP5.1Setup and configure connections to database2TP5.2Test sets of data from online database in the authentication system3TP<br /> TP5.45TP5.4TP6.1Extract and display acceptance and rejection rates and recognition statistics26TP6.2Examination ProductsTable 122 Examination<br /> ProductsProduct DeliveredTask IDTask DescriptionEffort(weeks)WhoEX1.1Research and complete PID21EX1.2Hong WeiEX2.1Write up log book and project<br /> progress review32EX2.2Hong WeiEX3.1Complete progress report checklist3EX3.23EX3.3Hong WeiEX4.1Project review demonstration of system progress34EX<br /> Hong WeiEX5.1Design and create poster1Hong Wei5EX6.1Write up scarp extract1Hong Wei6EX7.1Write up scarp paper1Hong Wei7EX8.1Write up final report2EX<br /> EX9.1Preparation for final demo to examiners1Hong Wei9EX10.1Preparation for scarp presentation110EX11.1Archive project111EX11.2Hong WeiTime Plan for<br /> the proposed Project workPlan for the proposed Project work10.3.1 < Table 123 Time Plan Technical ProductsProduct / Product<br /> the project start date here>Pre-TermAUTUMN TERM (weeks)BreakSPRING TERM (weeks)BreakSUMMER TERM(exams)1-23-45-67-89-10111-23-45-67-89-1011Product<br /> Graphical User InterfaceProduct 2: Capturing and storing images as graphical files.Product 3: Computing Face DetectionProduct 4:<br /> RecognitionProduct 5: Integrate Face Database into systemProduct 6: Display recognition results displaying rejection and<br /> Table 123 Time Plan Examination ProductsProduct / Product phaseSTART DATE: <enter the project start date here>Pre-TermAUTUMN TERM (weeks)BreakSPRING<br /> TERM (weeks)BreakSUMMER TERM(exams)1-23-45-67-89-10111-23-45-67-89-1011PIDAutumn Term Week 6 Logbook CheckProject Progress ReviewSpring Term Week<br /> DemonstrationPosterSCARP AbstractSCARP PaperFinal ReportDemonstration to Internal ExaminersSCARP PresentationProject Archive CDAppendix 2package<br /> application;import java.awt.image.BufferedImage;import java.awt.image.DataBufferByte;import java.awt.image.Raster;import java.io.ByteArrayInputStream<br /> import java.io.IOException;import java.nio.charset.Charset;import java.nio.file.Files;import java.nio.file.Paths;import java.util.ArrayList;import<br /> java.util.List;import org.opencv.core.Mat;import org.opencv.core.MatOfByte;import org.opencv.imgcodecs.Imgcodecs;import Jama.Matrix;import javafx<br /> scene.image.Image;import javafx.scene.image.PixelWriter;import javafx.scene.image.WritableImage;public class AppTools {/** * Converts a buffered<br /> image into 2d array * @param bufferdImage bi * @return double[][] returnArray */protected int[][] buffImg2array(BufferedImage bi) {int cols =<br /> getWidth();int rows = bi.getHeight();int returnArray[][] = new int[cols][rows];for (int i = 0; i < cols; i++) {for (int j = 0; j <<br /> returnArray[i][j] = bi.getRGB(i, j);}}return returnArray;}protected WritableImage buffToWriteImage(BufferedImage bi) { WritableImage wr = null;</w:t<br /> if (bi != null) {</w:t>< wr = new WritableImage(bi.getWidth(), bi.getHeight());</w:t></w:r PixelWriter pw = wr.getPixelWriter();</w:t></w:r for (int<br /> x = 0; x &lt; bi.get< bi.getWidth(); x++) { for (int y = 0; y &lt; bi.getHeig< bi.getHeight(); y++) { pw.setArgb(x, y, bi.getRGB(x, y));</w:t></w:r<br /> w:p>< }</w:t></w:r></w }</w:t></w:r }</w:t>< return wr;</w:t><}// source:// http://answers.opencv.org/question/10344/opencv-java-load-image-to-gui<br /> Converts an OpenCV Mat to buffered image  * @param Mat m * @return The output can be assigned either to BufferedImage or<br /> BufferedImage Mat2BufferedImage(Mat m)<a href='http://stackoverflow.com/questions/15670933/opencv-java-load-image-to-gui' class="matched-text" title='http://stackoverflow.com/questions/15670933/opencv-java-load-image-to-gui' target='_blank'> {int type = BufferedImage.TYPE_BYTE_GRAY;if (m.channels() > 1) {type = BufferedImage.TYPE_3BYTE_BGR;}int<br /> bufferSize = m.channels() * m.cols() * m.rows();byte[] b = new byte[bufferSize];m.get(0, 0, b); // get all the pixelsBufferedImage</a> image<a href='http://stackoverflow.com/questions/15670933/opencv-java-load-image-to-gui' class="matched-text" title='http://stackoverflow.com/questions/15670933/opencv-java-load-image-to-gui' target='_blank'> = new<br /> BufferedImage(m.cols(), m.rows(), type);final byte[] targetPixels = ((DataBufferByte) image.getRaster().getDataBuffer()).getData();System.arraycopy(b<br /> targetPixels, 0, b.length);return image;}/** *</a> Converts a buffered image to java Image * @param bufferdimage bi * @return Image<br /> WritableImage bufferedImg2Img(BufferedImage bi) {WritableImage newImage = null;if (bi != null) {// create writable image with same width and height<br /> as buff imagenewImage = new WritableImage(bi.getWidth(), bi.getHeight());PixelWriter pixWrite = newImage.getPixelWriter();for (int x = 0; x < bi<br /> getWidth(); x++) {for (int y = 0; y < bi.getHeight(); y++) {// get pixel value at x and y co-ordinatepixWrite.setArgb(x, y, bi.getRGB(x, y<br /> elseSystem.out.println("buffered image is empty");return newImage;}/** * Converts an OpenCV Mat to java Image * @param Mat frame * @return new Image<br /> protected Image Mat2Image(Mat frame) {// temporary bufferMatOfByte buffer = new MatOfByte();// encode image frame into PNG formatImgcodecs.imencode<br /> PNG", frame, buffer);// build image from encoded buffered datareturn new Image(new ByteArrayInputStream(buffer.toArray()));}protected double<br /> squareNonMatrix(double[][] data) { double[][] squaredNMResult = new double[data.length][data[0].length]; for (int i = 0; i < data.length; ++i) for<br /> int j = 0; j < data[i].length; ++j) squaredNMResult[i][j] = data[i][j];  for (int i = 0; i < data.length; ++i) {  for (int j =<br /> j) {  squaredNMResult[i][j] = squaredNMResult[i][j] * squaredNMResult[i][j];  }  } return squaredNMResult; <br /> double[] matrix1, double[] matrix2) {double[] result = new double[matrix1.length];for (int i = 0; i < result.length; ++i)result[i] = matrix1[i<br /> matrix2[i];return result;}protected double[][] subtractFromEachRow(double[][] data, double[] data2subtract) {  double[][] subtractMatResult = new<br /> double[data.length][data2subtract.length];  for (int i = 0; i < data.length; ++i)  for (int j = 0; j < data2subtract.length; ++j) <br /> i][j] = data[i][j];  for (int i = 0; i < data.length; ++i) {  for (int j = 0; j < data2subtract.length; ++j)<br /> subtract[j];  }  }  return subtractMatResult;  } protected String getMatrix2dFileString(double[][] input) {List<List<Double>> list<br /> List<Double>>(input.length);for (int i = 0; i < input.length; ++i) {List<Double> list2 = new ArrayList<Double>(input[i].length);for (int j = 0; j<br /> input[i].length; ++j) {list2.add(new Double(input[i][j]));}list.add(list2);}return getMatrix2dFileString(list);}protected String getMatrix<br /> dFileString(List<List<Double>> matrix) {StringBuffer str = new StringBuffer();for (int i = 0; i < matrix.size(); ++i) {for (int j = 0; j <<br /> i).size(); ++j) {boolean isEnd = j == matrix.get(i).size() - 1;str.append(String.format("%.5f%s", matrix.get(i).get(j), isEnd ? "" : ", "));}str<br /> append(System.lineSeparator());}return str.toString();}protected double[] multiply1DMatrix(double[] weights, Matrix subMatrix) {double[] returnVal<br /> new double[subMatrix.getColumnDimension()];for (int i = 0; i < returnVal.length; ++i) {double[] column = getColumn(subMatrix, i);double sum = 0;for<br /> int j = 0; j < column.length; ++j)sum += weights[j] * column[j];returnVal[i] = sum;}return returnVal;}protected double[] add1DMatrix(double[] m<br /> double[] m2) {double[] returnVal = new double[m1.length];for (int i = 0; i < returnVal.length; ++i)returnVal[i] = m1[i] + m2[i];return returnVal<br /> private double[] getColumn(Matrix m, int column) {double[] col = new double[m.getRowDimension()];for (int i = 0; i < m.getRowDimension(); ++i)col[i<br /> m.get(i, column);return col;}protected void print1dToFile(String fileName, double[] array) {StringBuffer str = new StringBuffer();for (int i = 0; i<br /> array.length; ++i) {boolean isEnd = i == array.length - 1;str.append(String.format("%.5f%s", array[i], isEnd ? "" : ", "));}List<String> toWrite<br /> new ArrayList<String>(1);toWrite.add(str.toString());try {Files.write(Paths.get(fileName), toWrite, Charset.forName("UTF-8"));} catch (IOException e<br /> e.printStackTrace();}}protected void print2dArrayToFile(String filename, double[][] matrix) {String fileContents = getMatrix2dFileString(matrix);List<br /> String> toWrite = new ArrayList<String>(1);toWrite.add(fileContents);try {Files.write(Paths.get(filename), toWrite, Charset.forName("UTF-8"));} catch<br /> IOException e) {e.printStackTrace();}}protected void print2dListToFile(String filename, List<List<Double>> matrix) {String fileContents = getMatrix<br /> dFileString(matrix);List<String> toWrite = new ArrayList<String>(1);toWrite.add(fileContents);try {Files.write(Paths.get(filename), toWrite, Charset<br /> forName("UTF-8"));} catch (IOException e) {e.printStackTrace();}}protected double[][] bufferedImageTo2DArray(BufferedImage bi) {Raster raster = bi<br /> getData();int width = raster.getWidth();int height = raster.getHeight();double[][] returnArray = new double[width][height];for (int i = 0; i < width<br /> i) {for (int j = 0; j < height; ++j) {returnArray[i][j] = raster.getSample(i, j, 0);}}return returnArray;}protected int getMinValue(int[] data2) {int<br /> minVal = Integer.MAX_VALUE;for (int i = 0; i < data2.length; ++i) {minVal = Math.min(minVal, data2[i]);}return minVal;}protected int getMaxValue(int<br /> data) {int maxVal = Integer.MIN_VALUE;for (int i = 0; i < data.length; ++i)maxVal = Math.max(maxVal, data[i]);return maxVal;}protected double<br /> getMinValue(double[] data2) {double minVal = Double.MAX_VALUE;for (int i = 0; i < data2.length; ++i) {minVal = Math.min(minVal, data2[i]);}return<br /> minVal;}protected double getMaxValue(double[] data) {double maxVal = Double.NEGATIVE_INFINITY;for (int i = 0; i < data.length; ++i)maxVal = Math.max<br /> maxVal, data[i]);return maxVal;}}SE1IP1121009807SE3IP11Tom BedfordA-FACE<br /></p>
                        
                        
                    </div>
                    
                </div> 
            </div>

            <div id="footer">
                <div id="footermenu">
                    <div id="col1">
                        <ul>
                            <li>
                                <a title="Plagiarism detection software" href="http://www.scanmyessay.com/plagiarism-detection-software.php">Plagiarism Detection Software</a>
                            </li>
                            <li>
                                <a title=" Plagiarism Test" href="http://www.scanmyessay.com/plagiarism-test.php">Plagiarism Test </a>
                            </li>
                            <li>
                                <a title="Plagiarism Detector" href="http://www.scanmyessay.com/plagiarism-detector.php">Plagiarism Detector</a>
                            </li>
                            <li>
                                <a title="Detect Plagiarism" href="http://www.scanmyessay.com/detect-plagiarism.php">Detect Plagiarism</a>
                            </li>
                        </ul>
                    </div>
                    <div id="col2">
                        <ul>
                            <li>
                                <a title="Essay Checker" href="http://www.scanmyessay.com/essay-checker.php">Essay Checker</a> 
                                | <a href="http://www.scanmyessay.com/free-check-for-plagiarism.php">Free Check for Plagiarism</a>
                            </li>
                            <li>
                                <a title="Free lesson plans" href="http://www.scanmyessay.com/lesson-plans.php">Lesson plans</a>
                            </li>
                            <li>
                                <a title="Avoid plagiarism" href="http://www.scanmyessay.com/avoid-plagiarism.php">Avoid Plagiarism</a>
                            </li>
                            <li>
                                <a title="Plagiarism Check" href="http://www.scanmyessay.com/plagiarism-check.php">Plagiarism Check</a>
                            </li>
                        </ul>
                    </div>
                    <div id="col3">
                        <ul>
                            <li>
                                <a title="Plagiarism prevention software" href="http://www.scanmyessay.com/plagiarism-prevention.php">Plagiarism Prevention</a>
                            </li>
                            <li>
                                <a title="Turnitin" href="http://www.scanmyessay.com/turnitin.php">Turnitin </a> | <a href="http://www.scanmyessay.com/check-for-plagiarism-free.php">Check for Plagiarism Free</a>
                            </li>
                            <li>
                                <a title="Editing services" href="http://www.scanmyessay.com/essay-marking/index.php">Editing Services</a>
                            </li>
                            <li>
                                <a title="Free Scanner Software" href="http://www.essaycoursework.com/coursework-writing.php">Coursework writing</a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div id="footerbottom">
                    <p>
                        Copyright © 2012 All Rights Reserved. 
                        <a href="http://www.scanmyessay.com">Scan My Essay</a> 
                        - Free Plagiarism Scanner, Checker and Detection Tool.  
                        Viper and ScanMyEssay.com are trading names of Angel Business Limited, 
                        a Company registered in England and Wales with Company Registration No: 07344835, 
                        The Loft, 3 Plumptre Street, The Lace Market, Nottingham NG1 1JL | 
                        <a href="http://www.scanmyessay.com/viper-keygen-crack.php">Warning - Viper Keygen / Viper Crack</a>
                    </p>
                    <p>
                        Please note that by using ScanMyEssay.com, VIPER and any other  software or resources on the ScanMyEssay Website, you are signifying  your agreement
                        to our <a href="http://www.scanmyessay.com/terms.php">terms and conditions</a>, and our <a href="http://www.scanmyessay.com/privacy-policy.php">privacy policy</a> | <a href="http://www.scanmyessay.com/sitemap.xml">XML sitemap</a> 
                        | <a href="http://www.scanmyessay.com/ror.xml">ROR</a> 
                        | <a href="http://www.scanmyessay.com/urllist.txt">TXT</a>
                        | <a href="http://www.scanmyessay.com/sitemap.html">HTML</a>
                        | <a href="http://www.scanmyessay.com/sitemap.php">PHP</a> | <a href="http://cn.scanmyessay.com">剽窃检查</a>
                        | <a href="http://es.scanmyessay.com">Verificador de plagio gratuito</a> 
                        | <a href="http://fr.scanmyessay.com/">Détecteur de plagiat gratuit</a> 
                        | <a href="http://in.scanmyessay.com/">Viper साहित्यिक चोरी जांचने का एक निशुल्क साधन...</a>

                    </p>
                </div> 
            </div>

        </div>
         
    </body>
</html>
